# Environment config (Do not use with Discrete action space )
env:
  type: 'pybullet-robotics'
  # Classic control env name
  name : 'InvertedPendulumBulletEnv-v0'
  # seed
  seed: 543
  # solution rewards
  env_solution: 195

# Agent config
agent:
  # type of agent
  agent_type: 'ddpg'
  # model type
  model_type: 'mlp'
  # Learning rate for the actor network
  actor_lr : 0.0001
  # Learning rate for the critic network
  critic_lr : 0.001
  # optimizer name
  opt_name: 'adam'
  # Bellman equation reward discount
  gamma : 0.99
  # Estimated GAE with TD(lambda)
  tau: 0.001
  # replay buffer size:
  replay_size: 10000
  # stacked input state length
  state_len : 1
  # state_size :=  state_len + [input_shape]
  input_shape: [5]
  # action_size
  action_size: 1
  # transform the input
  input_transforms:
  # init_weights:
  init_weights: False
  # contious control
  continous: True
  # norm of gradient clipping, leave empty for no clipping
  grad_clip:

train:
  # Number of training episodes
  n_train_episodes : 1000
  # Max steps in each episode
  max_steps : 200
  # Exploration time steps
  n_exploration_steps: 10000
  # batch size for ddpg
  batch_size: 64
  # model location
  model_dest: /data/experiments/agent-of-control/23-01-2020-inverted-pendulum-ddpg
  # save model every save_model steps
  save_model: 10000
  # update target every update_target episodes
  update_target: 4
  # policy update
  policy_update: 4

test:
  # Number of testing episodes
  n_test_episodes : 5
  # Max steps in each episode
  max_steps : 1000
  # path where to save played video
  state_dest: /data/experiments/agent-of-control/23-01-2020-inverted-pendulum-ddpg/states
