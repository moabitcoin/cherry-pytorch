# Environment config
env:
  # Enviroment type
  type: 'atari'
  # AtariPreprocessing has default frame_skip=4
  name : 'BreakoutNoFrameskip-v4'
  # random game seed
  seed: 543

# Agent config
agent:
  # Agent type
  agent_type: 'dqn'
  # model type
  model_type: 'convnet-large'
  # Learning rate for the agent
  lr : 0.0000625
  # type of the optimizer
  opt_name: 'adam'
  # gradient clipping [-grad_clip, +grad_clip], leave empty for no clipping
  grad_clip: 1
  # Bellman equation reward discount
  gamma : 0.99
  # maximum exploration likelihood
  max_eps : 0.9
  # minimum exploration likelihood
  min_eps : 0.1
  # exploration likelihood decay
  eps_decay : 10000000
  # crop shape leave empty for no center cropping
  crop_shape :
  # frame shape full resolution frame would be resized to this size
  input_shape : [84, 84]
  # state size input_shape + [state_size] tensor as enviroment representation
  state_size : 4
  # action space size
  action_size: 3
  # memory replay size
  replay_size : 1000000
  # input state transforms
  input_transforms: ['resize']

train:
  # Number of training episodes
  n_train_episodes : 5000
  # Max steps in each episode
  max_steps : 10000
  # batch size
  batch_size: 64
  # model location
  model_dest: /data/experiments/agent-of-atari/08-01-2019-Breakout-v0-dqn
  # update target every update_target steps
  update_target: 10000
  # save model every save_model steps
  save_model: 100000
  # update model with backprop every policy_update steps
  policy_update: 4


test:
  # Number of testing episodes
  n_test_episodes : 1
  # Max steps in each episode
  max_steps : 10000
  # path where to save played video
  state_dest: /data/experiments/agent-of-atari/08-01-2019-Breakout-v0-dqn/states
