# Environment config
env:
  type : 'doom'
  name : 'basic'
  seed : 543

# Agent config
agent:
  # type
  agent_type : 'dqn'
  # model type
  model_type : 'convnet-medium'
  # Learning rate for the agent
  lr : 0.001
  # optimizer
  opt_name: 'rmsprop'
  # gradient clipping [-grad_clip, +grad_clip], leave empty for no clipping
  grad_clip: 10
  # Bellman equation reward discount
  gamma : 0.99
  # maximum exploration likelihood
  max_eps : 0.9
  # minimum exploration likelihood
  min_eps : 0.1
  # exploration likelihood decay
  eps_decay: 50000
  # crop shape leave empty for no center cropping, leave empty for no cropping
  crop_shape: [224, 224]
  # frame shape full resolution frame would be resized to this size, leave empty for no cropping
  input_shape : [84, 84]
  # state size input_shape + [state_size] tensor as enviroment representation
  state_size : 4
  # action space size
  action_size: 3
  # memory replay size
  replay_size : 100000
  # input state transforms
  input_transforms: ['crop', 'resize']

train:
  # Number of training episodes
  n_train_episodes : 200
  # Max steps in each episode
  max_steps : 1000
  # batch size
  batch_size: 64
  # model location
  model_dest: /data/experiments/agent-of-doom/08-01-2019-320x240-basic-dqn
  # update target every update_target episodes
  update_target: 1000
  # save model every save_model episodes
  save_model: 10000
  # policy update
  policy_update: 4

test:
  # Number of testing episodes
  n_test_episodes : 1
  # Max steps in each episode
  max_steps : 1000
  # path where to save played video
  state_dest: /data/experiments/agent-of-doom/08-01-2019-320x240-basic-dqn/states
